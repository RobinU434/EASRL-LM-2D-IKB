\chapter{Conclusion}\label{chap:conclusion}

In this thesis, we have explored the integration of latent models, specifically pre-trained Variational Autoencoder (VAE) decoders and supervised models, into Reinforcement Learning (RL) frameworks with the aim of expanding the action space capabilities of RL agents. Our research was evaluated using a benchmark environment: solving a 2D Inverse Kinematics problem on a robot arm with a variable number of joints, denoted as $N$. The study investigated how the incorporation of latent models enhances the RL agent's performance in handling complex action spaces.

\textbf{Key Findings}

The key findings of this research can be summarized as follows:

\begin{enumerate}
    \item \textbf{Latent Model Integration}: The integration of a pre-trained decoder from a VAE with the Soft Actor-Critic (SAC) algorithm shows promise in addressing high-dimensional action spaces. However, it is not yet on par with standard approaches and requires further improvement.
    \item \textbf{RL Benchmark Environment}: The 2D inverse kinematics benchmark environment has proven to be a suitable and flexible candidate for benchmarking different RL algorithms, offering a standardized platform for assessing agent performance.
\end{enumerate}

\textbf{Theoretical Contributions}

Our research contributes to RL methodology and theory in several ways:

\begin{itemize}
    \item \textbf{Advancements in RL}: This research advances RL methodology by introducing a novel approach for handling high-dimensional action spaces and expanding the scope of RL applications.
    \item \textbf{Latent Model Integration}: We contribute to the theoretical understanding of integrating latent models into RL, addressing aspects in design, training, and utilization.
    \item \textbf{Action Space Abstraction}: Our work advances the theory of action space abstraction, demonstrating the effectiveness of latent models in simplifying complex action spaces.
\end{itemize}

\textbf{Limitations}

While our research provides valuable insights, it is essential to acknowledge its limitations. We observed a performance gap between expected and actual results, particularly in scenarios involving a high number of joints. Additionally, our approach fell short when compared to baseline experiments, raising questions about its effectiveness. Challenges related to scalability, the choice of latent models, and the complexity of the RL environment may have influenced the outcomes. Further considerations include data efficiency, generalizability to other RL tasks, and the specific complexities of the 2D Inverse Kinematics problem.

\textbf{Future Directions}

Future research directions encompass refining latent models for improved action space expansion. This may involve exploring advanced generative models such as Generative Adversarial Networks (GANs) or incorporating additional latent model refinement during the RL training process. Extensive hyperparameter tuning should be explored to optimize model and algorithm parameters, enhancing overall performance and efficiency. Investigating data augmentation techniques and designing benchmark environments that mirror real-world complexities will improve the practicality of the proposed approach. Additionally, future avenues include transfer learning, multi-agent RL applications, and interdisciplinary collaborations to expand the applicability of latent model-enhanced RL.

\textbf{Key Takeaways}

Readers of this thesis will gain insights into the importance of expanding action spaces in Reinforcement Learning (RL) through the integration of latent models, such as Variational Autoencoders (VAEs) and supervised models. They will also understand the challenges and limitations faced in achieving performance improvements, particularly in scenarios with a high number of joints. The thesis highlights the significance of benchmarking RL agents in various environments and provides directions for future research, including advanced latent models, hyperparameter optimization, and ethical considerations. Ultimately, readers will appreciate the real-world relevance of this research, particularly in fields like robotics and automation, and recognize the iterative nature of scientific inquiry in advancing RL capabilities.
